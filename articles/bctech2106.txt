Optimize the data scraper program to easily accommodate large files and solve OOM errors

Client:A leading tech firm in India

Industry Type:IT Services

Services:SAAS services, Marketing services, Business consultant

Organization Size:100+

Building a large data warehouse that houses projects and tenders data from all over the world that is to be collected from official government websites, multilateral banks, state and local government agencies, data aggregating websites, etc.

We had tried multiple solutions to prevent the program from running out of memory. We used python pandas techniques to control the use of memory which worked for some files and did not work for others. Provided more solutions using vaex ,dask module and datatables.

Desired changes to the code and committing them to github.

System specs requirement was the main issue during this project because the RAM available was too less and got used up quickly.

Team viewer to use remote desktop which had higher specs would be sufficient enough to solve the problem.

